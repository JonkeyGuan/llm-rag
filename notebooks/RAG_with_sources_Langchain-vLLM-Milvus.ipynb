{
    "cells": [
     {
      "cell_type": "markdown",
      "id": "2a331fd6",
      "metadata": {},
      "source": [
       "## RAG example with Langchain, Milvus, and vLLM\n",
       "\n",
       "Requirements:\n",
       "- A Milvus instance, either standalone or cluster.\n",
       "- Connection credentials to Milvus must be available as environment variables: MILVUS_USERNAME and MILVUS_PASSWORD.\n",
       "- A vLLM inference endpoint. In this example we use the OpenAI Compatible API."
      ]
     },
     {
      "cell_type": "markdown",
      "id": "e712b3e8-f406-4387-9188-3e2f20a6841f",
      "metadata": {},
      "source": [
       "### Needed packages and imports"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d4a359bd-4f69-4e88-82c0-5763c26aa0af",
      "metadata": {
       "tags": []
      },
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "\n",
         "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
         "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
        ]
       }
      ],
      "source": [
       "!pip install -q einops==0.7.0 langchain==0.1.9 pymilvus==2.3.6 sentence-transformers==2.5.0 openai==1.13.3"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 2,
      "id": "83e11d23-c0ad-4875-b67f-149fc8b14725",
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "import os\n",
       "from langchain.callbacks.base import BaseCallbackHandler\n",
       "from langchain.chains import RetrievalQA\n",
       "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
       "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
       "from langchain_community.llms import VLLMOpenAI\n",
       "from langchain.prompts import PromptTemplate\n",
       "from langchain_community.vectorstores import Milvus"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "9cd4537b",
      "metadata": {},
      "source": [
       "#### Bases parameters, Inference server and Milvus info"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 4,
      "id": "51baf1a6-4111-4b40-b43a-833438bdc222",
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "# Replace values according to your Milvus deployment\n",
       "INFERENCE_SERVER_URL = \"http://vllm.vllm.svc.cluster.local:8000/v1\"\n",
       "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
       "MAX_TOKENS=1024\n",
       "TOP_P=0.95\n",
       "TEMPERATURE=0.01\n",
       "PRESENCE_PENALTY=1.03\n",
       "MILVUS_HOST = \"vectordb-milvus.milvus.svc.cluster.local\"\n",
       "MILVUS_PORT = 19530\n",
       "MILVUS_USERNAME = os.getenv('MILVUS_USERNAME')\n",
       "MILVUS_PASSWORD = os.getenv('MILVUS_PASSWORD')\n",
       "MILVUS_COLLECTION = \"collection_nomicai_embeddings\""
      ]
     },
     {
      "cell_type": "markdown",
      "id": "fe4c1b1a",
      "metadata": {},
      "source": [
       "#### Initialize the connection"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bbb6a3e3-5ccd-441e-b80d-427555d9e9f6",
      "metadata": {
       "tags": []
      },
      "outputs": [
       {
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "/opt/app-root/lib64/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
         "  warnings.warn(\n",
         "<All keys matched successfully>\n"
        ]
       }
      ],
      "source": [
       "model_kwargs = {'trust_remote_code': True}\n",
       "embeddings = HuggingFaceEmbeddings(\n",
       "    model_name=\"nomic-ai/nomic-embed-text-v1\",\n",
       "    model_kwargs=model_kwargs,\n",
       "    show_progress=False\n",
       ")\n",
       "\n",
       "store = Milvus(\n",
       "    embedding_function=embeddings,\n",
       "    connection_args={\"host\": MILVUS_HOST, \"port\": MILVUS_PORT, \"user\": MILVUS_USERNAME, \"password\": MILVUS_PASSWORD},\n",
       "    collection_name=MILVUS_COLLECTION,\n",
       "    metadata_field=\"metadata\",\n",
       "    text_field=\"page_content\",\n",
       "    drop_old=False\n",
       "    )"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "b72a3a2b",
      "metadata": {},
      "source": [
       "#### Initialize query chain"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ed8fd396-0798-45c5-8969-6b6ede134c77",
      "metadata": {
       "tags": []
      },
      "outputs": [],
      "source": [
       "template=\"\"\"    <s>[INST] <<SYS>>\n",
       "    你是一个乐于助人、尊重他人、诚实的助手，名叫：小助手，正在回答问题。\n",
       "    \n",
       "    您将得到一个需要回答的问题，以及一个为您提供信息的上下文。您必须尽可能根据此上下文回答问题。\n",
       "    \n",
       "    在保证安全的情况下，始终尽可能提供有用的答案。您的答案不应包含任何有害、不道德、种族主义、性别歧视、有毒、危险或非法的内容。请确保您的回答在社会上不偏不倚，并且本质上是积极的。\n",
       "    \n",
       "    请用中文回答问题。\n",
       "    \n",
       "    如果问题没有任何意义，或者事实不连贯，请解释原因，而不是回答不正确的内容。如果您不知道问题的答案，请不要分享虚假信息。\n",
       "    <</SYS>>\n",
       "    \n",
       "    Context: \n",
       "    {context}\n",
       "    \n",
       "    Question: {question} [/INST]\n",
       "\"\"\"\n",
       "\n",
       "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
       "\n",
       "llm =  VLLMOpenAI(\n",
       "    openai_api_key=\"EMPTY\",\n",
       "    openai_api_base=INFERENCE_SERVER_URL,\n",
       "    model_name=MODEL_NAME,\n",
       "    max_tokens=MAX_TOKENS,\n",
       "    top_p=TOP_P,\n",
       "    temperature=TEMPERATURE,\n",
       "    presence_penalty=PRESENCE_PENALTY,\n",
       "    streaming=True,\n",
       "    verbose=False,\n",
       "    callbacks=[StreamingStdOutCallbackHandler()]\n",
       ")\n",
       "\n",
       "qa_chain = RetrievalQA.from_chain_type(\n",
       "        llm,\n",
       "        retriever=store.as_retriever(\n",
       "            search_type=\"similarity\",\n",
       "            search_kwargs={\"k\": 4}\n",
       "            ),\n",
       "        chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
       "        return_source_documents=True\n",
       "        )\n",
       "\n",
       "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
     },
     {
      "cell_type": "markdown",
      "id": "3a45ad23",
      "metadata": {},
      "source": [
       "#### Query example"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 8,
      "id": "105d2fd1-f36c-409d-8e52-ec6d23a56ad1",
      "metadata": {
       "tags": []
      },
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "要创建一个 Data Science Project，请按照以下步骤操作：\n",
         "\n",
         "1. 登录 Red Hat OpenShift AI。\n",
         "2. 从 OpenShift AI 仪表板中，点击“Data Science Projects”。\n",
         "3. 点击“Create data science project”。\n",
         "4. 输入您的数据科学项目的名称。\n",
         "5. 可选：编辑资源名称，资源名称必须由小写字母、数字、连字符组成，并且必须以字母或数字开头和结尾。\n",
         "6. 输入您的数据科学项目的描述。\n",
         "7. 点击“Create”。\n",
         "\n",
         "创建后，您的数据科学项目将显示在“Data Science Projects”页面上。从此页面，您可以创建工作台、添加集群存储和数据连接、导入管道、部署模型等。"
        ]
       }
      ],
      "source": [
       "question = \"如何创建一个 Data Science Project?\"\n",
       "result = qa_chain.invoke({\"query\": question})"
      ]
     },
     {
      "cell_type": "markdown",
      "id": "97d75d0c",
      "metadata": {},
      "source": [
       "#### Retrieve source"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 9,
      "id": "acda357e-558a-4879-8ad8-21f0567f2f2e",
      "metadata": {
       "tags": []
      },
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2.9/html-single/working_on_data_science_projects/index\n",
         "https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2.9/html-single/openshift_ai_tutorial_-_fraud_detection_example/index\n",
         "https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2.9/html-single/getting_started_with_red_hat_openshift_ai_self-managed/index\n"
        ]
       }
      ],
      "source": [
       "def remove_duplicates(input_list):\n",
       "    unique_list = []\n",
       "    for item in input_list:\n",
       "        if item.metadata['source'] not in unique_list:\n",
       "            unique_list.append(item.metadata['source'])\n",
       "    return unique_list\n",
       "\n",
       "results = remove_duplicates(result['source_documents'])\n",
       "\n",
       "for s in results:\n",
       "    print(s)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "6530b005-c32c-40cc-b859-50e25eeb08ab",
      "metadata": {},
      "outputs": [],
      "source": []
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3.9",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 5
   }
   